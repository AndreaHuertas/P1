<h1 align='center'>
 <b>Proyecto  Individual I</b>
</h1>

***
<h1 align='center'>
<b>Movie RecommendationğŸ¬ğŸ¿</b>
</h1>

<p align="center">
  <img src="Image/logo.png" />
</p>

***
En este proyecto de Machine Learning, asumirÃ© el rol de un _Data Engineer_ y realizarÃ© todos los procesos necesarios, desde el tratamiento y recolecciÃ³n de datos hasta el entrenamiento y mantenimiento del modelo de ML a medida que llegan nuevos datos. El proyecto se desarrollarÃ¡ en varias etapas, que incluyen:


**Proceso de ETL (ExtracciÃ³n, TransformaciÃ³n, Carga)**: En el archivo _ETL.py_, se llevÃ³ a cabo el proceso de extracciÃ³n de datos de diversas fuentes, la transformaciÃ³n de los datos para su limpieza y preparaciÃ³n, y finalmente la carga de los datos en un formato adecuado ( archivo _movies_final.csv_) para su posterior anÃ¡lisis y entrenamiento del modelo.

**AnÃ¡lisis Exploratorio de Datos (EDA)**: En el notebook _EDA.ipynb_, se realizarÃ¡ un anÃ¡lisis exhaustivo de los datos recopilados. Esto incluirÃ¡ la visualizaciÃ³n de los datos, la identificaciÃ³n de patrones, la detecciÃ³n de valores atÃ­picos y la generaciÃ³n de ideas y preguntas relevantes para el problema que estamos abordando.

**Desarrollo del Modelo de Machine Learning**: En el archivo _ml_model.py_, se implementarÃ¡ un modelo de machine learning utilizando el algoritmo de vecinos mÃ¡s cercanos (K-Nearest Neighbors). Este modelo se entrenarÃ¡ utilizando los datos recopilados y preparados en las etapas anteriores.

**ImplementaciÃ³n de la Interfaz**: En el archivo _main.py_, se crearÃ¡ una interfaz utilizando la biblioteca FastAPI. Esta interfaz permitirÃ¡ a los usuarios interactuar con el modelo de machine learning, proporcionando los datos de entrada necesarios y obteniendo las predicciones correspondientes.

**Despliegue y ImplementaciÃ³n**: Finalmente, se llevarÃ¡ a cabo el despliegue del proyecto utilizando Streamlit y se realizarÃ¡ la implementaciÃ³n en un entorno de producciÃ³n utilizando Render. Esto permitirÃ¡ que el modelo y la interfaz estÃ©n disponibles en lÃ­nea y sean accesibles para los usuarios.

A travÃ©s de estas etapas, se abordarÃ¡n todos los aspectos clave del proceso de desarrollo de un proyecto de Machine Learning, desde la recolecciÃ³n y preparaciÃ³n de datos hasta la implementaciÃ³n de un modelo funcional y su despliegue en un entorno de producciÃ³n.

***

### **ğŸ“’InformaciÃ³n General**
***
1. Desde el _Anaconda Prompt_ se crea un nuevo entorno y se instalan todas las librerÃ­as necesarias.

```
#Creamos un nuevo entorno
conda create --name newApi

#Instalamos las librerÃ­as 
conda install pandas
conda install scikit-learn
pip install fastapi
pip install "uvicorn[standar]"
pip install streamlit
```
2. Se realiza todo el proceso de ETL, de los datos proporcionados inicialmente, quedando como resultado el data set _movies_final.csv_.

3. Se realiza el anÃ¡lisis exploratorio de datos (EDA.ipynb), se examinan las variables cualitativas y cuantitativas de la base de datos. En el caso especÃ­fico de los tÃ­tulos de pelÃ­culas, se utiliza una nube de palabras para identificar las palabras mÃ¡s frecuentes.

<p align="center">
  <img src="Image/nube.png" />
</p>

4. Se crea el archivo _main.py_, donde se cargan las siguientes librerias:

* fastapi
* pandas

Dentro de este mismo archivo, se generan las siguientes funciones, encargadas del sistema de consultas:

* _movies_language(language)_: Calcula la cantidad de filmaciones producidas en el idioma de entrada.
* _duration_movies(movie)_: Calcula la duraciÃ³n de la pelÃ­cula de entrada y el aÃ±o de estreno. 
* _collection(collection)_: Al ingresar el nombre de la colecciÃ³n o saga de un grupo de pelÃ­culas, trae la cantidad de pelÃ­culas de la saga, ganancia total y promedio.
* votos_titulo(titulo): Al ingresar el tÃ­tulo de la pelÃ­cula, trae el tÃ­tulo, votos y votos promedio.
* _movie_country(country)_: Al ingresar el paÃ­s, retorna la cantidad de pelÃ­culas producidas en el paÃ­s ingresado.
* _get_director(director)_: Al ingresar el nombre del director, trae el nombre del director, tÃ­tulos de las pelÃ­culas realizadas, fecha de lanzamiento, retorno, presupuesto y ganancias.


5. Se crea el archivo _ml_model.py_, en el cual se cargan las siguientes librerias:

* pandas
* sklearn
* streamlit

En el archivo _ml_model.py_  se carga el dataset _movies_final.csv_, el que se siguen los siguientes pasos, para crear el modelo de machine learning:

* Se carga el dataset _movies_final.csv_ 
* Se toman las columnas 'title', 'collection_movie', 'original_language', 'genres', 'overview', 'popularity', 'production_companies', 'production_countries', 'release_date', 'actors', 'director', y se genera una sola columna llamada 'features', que combina a las anteriores.
* Se crea la matriz TF-IDF que captura la importancia relativa de los tÃ©rminos en cada documento en relaciÃ³n con el corpus.
* Se crea  una instancia del modelo de vecinos mÃ¡s cercanos y se entrena con la  matriz TF-IDF generada previamente en funciÃ³n de la similitud del coseno en el espacio de caracterÃ­sticas TF-IDF.
* Se generan las siguientes funciones: get_recomendations(), user_input, main. La primera se encarga de utiliza el modelo de vecinos mÃ¡s cercanos para encontrar pelÃ­culas similares a partir de un tÃ­tulo dado, y devuelve una lista de los tÃ­tulos de las pelÃ­culas recomendadas. La segunda gestiona las acciones del usuario y la tercera gestiona la aplicaciÃ³n principal.

6. Generamos nuestra aplicaciÃ³n web en el servidor, empleando el Anaconda Promt, de la siguiente manera:

```
#Para activar el ambiente donde tenemos nuestras librerÃ­as
conda activate env

#Vamos a nuestra carpeta de trabajo
cd rutaCarpeta

#Para  generar nuestra aplicaciÃ³n
rutaCarpeta>python ml_model.py

#Para ver nuestra aplicaciÃ³n enla web
rutaCarpeta>streamlit run ml_model.py

```
Vista previa de la aplicacion web, generada con streamlit.

<p align="center">
  <img src="Image/pan.png" />
</p>

7. Se realiza el deploy en del API de consultas de pelÃ­culas en <A HREF="https://render.com/">Render</A>.

8. Se realiza un video explicativo, que se puede encontrar en <A HREF="https://www.youtube.com/">youtube</A>.

***
## **ğŸ“Links**
* <A HREF="">API  de consultas de pelÃ­culas </A>.
 
* <A HREF="https://p1-6n55x3niz6b.streamlit.app/"> Recomendacion de pelÃ­culas.</A> 

## **ğŸ‘€Recomendaciones**
***
* Emplear solamente minÃºsculas.
* No hacer uso de caracteres especiales.

## **ğŸ“ˆTecnologÃ­as**
***
Una lista de tecnologÃ­as utilizadas en el proyecto:
* ğŸ[Python](https://docs.python.org/3/): Version 3.85
* ğŸ¼[Pandas](https://pandas.pydata.org/): Version 3.3.0
* ğŸ’»[Numpy](https://numpy.org/doc/): Version 3.2.0
* ğŸ“Š[scikit learn](https://scikit-learn.org/stable/): Version 1.1.3
* ğŸ“³[FastApi](https://fastapi.tiangolo.com/): Version 0.96.0
* ğŸ¦„[Uvicorn](https://www.uvicorn.org/): Version 0.22.0
* ğŸ–¥[Streamlimit](https://streamlit.io/): Version 1.23.1

## **Autor ğŸ§œâ€â™€ï¸**
***

* Andrea Huertas 
* correo electronico: andrehuertasg@gmail.com 
* linkedin: https://www.linkedin.com/in/luz-andrea-huertas-guerrero-30bb7a237/
